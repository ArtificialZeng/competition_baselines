{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('max_rows', 500)\n",
    "pd.set_option('max_colwidth', 200)\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, get_linear_schedule_with_warmup\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('oofs', exist_ok=True)\n",
    "os.makedirs('preds', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_json('Sohu2022_data/nlp_data/train.txt', lines=True)\n",
    "df_test = pd.read_json('Sohu2022_data/nlp_data/test.txt', lines=True)\n",
    "\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list()\n",
    "\n",
    "for idx, row in tqdm(df_train.iterrows()):\n",
    "    for entity in row['entity']:\n",
    "        di = dict()\n",
    "        di['id'] = f'{row[\"id\"]}_{entity}'\n",
    "        di['text'] = f'实体: {entity} [SEP] ' + row['content']\n",
    "        di['label'] = row['entity'][entity]\n",
    "        train_data.append(di)\n",
    "        \n",
    "df_train = pd.DataFrame(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = list()\n",
    "\n",
    "for idx, row in tqdm(df_test.iterrows()):\n",
    "    for entity in row['entity']:\n",
    "        di = dict()\n",
    "        di['id'] = f'{row[\"id\"]}'\n",
    "        di['text'] = f'实体: {entity} [SEP] ' + row['content']\n",
    "        test_data.append(di)\n",
    "        \n",
    "df_test = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label'] += 2\n",
    "df_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train['text'].apply(lambda x: len(x)).describe())\n",
    "display(df_test['text'].apply(lambda x: len(x)).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        super(Config, self).__init__()\n",
    "\n",
    "        self.SEED = 42\n",
    "        self.MODEL_PATH = 'hfl/chinese-roberta-wwm-ext'\n",
    "        self.NUM_CLASSES = df_train['label'].nunique()\n",
    "\n",
    "        # data\n",
    "        self.CLASSES_WEIGHTS = [] # weights   # or []\n",
    "        self.TOKENIZER = AutoTokenizer.from_pretrained(self.MODEL_PATH)\n",
    "        self.MAX_LENGTH = 512\n",
    "        self.BATCH_SIZE = 8\n",
    "        self.ACCUMULATION_STEPS = 1\n",
    "        self.N_FOLDS = 5\n",
    "\n",
    "        # model\n",
    "        self.DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.FULL_FINETUNING = True\n",
    "        self.LR = 2e-5\n",
    "        self.N_VALIDATE_DUR_TRAIN = 3\n",
    "        self.N_WARMUP = 0\n",
    "        self.SAVE_BEST_ONLY = True\n",
    "        self.EPOCHS = 3\n",
    "        self.USE_FGM = False\n",
    "        \n",
    "CONFIG = Config()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "np.random.seed(CONFIG.SEED)\n",
    "seed_torch(seed=CONFIG.SEED)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = CONFIG.DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentiDataset(Dataset):\n",
    "    def __init__(self, df, indices, set_type=None):\n",
    "        super(SentiDataset, self).__init__()\n",
    "\n",
    "        df = df.loc[indices]\n",
    "        self.texts = df['text'].values.tolist()\n",
    "        self.set_type = set_type\n",
    "        if self.set_type != 'test':\n",
    "            self.labels = df['label'].values.tolist()\n",
    "\n",
    "        self.tokenizer = CONFIG.TOKENIZER\n",
    "        self.max_length = CONFIG.MAX_LENGTH\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        tokenized = self.tokenizer.encode_plus(\n",
    "            self.texts[index],\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=False,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = tokenized['input_ids'].squeeze()\n",
    "        attention_mask = tokenized['attention_mask'].squeeze()\n",
    "\n",
    "        if self.set_type != 'test':\n",
    "            return {\n",
    "                'input_ids': input_ids.long(),\n",
    "                'attention_mask': attention_mask.long(),\n",
    "                'labels': torch.tensor(self.labels[index], dtype=torch.long),\n",
    "            }\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids.long(),\n",
    "            'attention_mask': attention_mask.long(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(CONFIG.MODEL_PATH)\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, CONFIG.NUM_CLASSES)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.bert(input_ids=input_ids,\n",
    "                                     attention_mask=attention_mask, \n",
    "                                     return_dict=False)\n",
    "        output = self.drop(pooled_output)\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_fn(model, valid_dataloader, criterion):\n",
    "    val_loss = 0\n",
    "    corrects = 0\n",
    "    model.eval()\n",
    "    for step, batch in tqdm(enumerate(valid_dataloader),\n",
    "                            total=len(valid_dataloader),\n",
    "                            desc='validing'):\n",
    "        b_input_ids = batch['input_ids'].to(device)\n",
    "        b_attention_mask = batch['attention_mask'].to(device)\n",
    "        b_labels = batch['labels'].to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids=b_input_ids, attention_mask=b_attention_mask)\n",
    "            loss = criterion(logits, b_labels)\n",
    "            val_loss += loss.item()\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            corrects += torch.sum(preds == b_labels)\n",
    "    avg_val_loss = val_loss / len(valid_dataloader)\n",
    "    avg_val_acc = corrects.cpu().numpy() / len(valid_dataloader) / CONFIG.BATCH_SIZE\n",
    "    print('Val loss:', avg_val_loss, 'Val acc:', avg_val_acc)\n",
    "    return avg_val_loss, avg_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_prob(model, dl):\n",
    "    probs = []\n",
    "    model.eval()\n",
    "    for step, batch in tqdm(enumerate(dl),\n",
    "                            total=len(dl),\n",
    "                            desc='infering'):\n",
    "        b_input_ids = batch['input_ids'].to(device)\n",
    "        b_attention_mask = batch['attention_mask'].to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids=b_input_ids, attention_mask=b_attention_mask)\n",
    "            logits = logits.cpu().numpy()\n",
    "            probs.extend(logits)\n",
    "    probs = np.array(probs)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, train_dataloader, valid_dataloader, criterion, optimizer, scheduler, epoch):\n",
    "    # we validate config.N_VALIDATE_DUR_TRAIN times during the training loop\n",
    "    nv = CONFIG.N_VALIDATE_DUR_TRAIN\n",
    "    temp = len(train_dataloader) // nv\n",
    "    temp = temp - (temp % 100)\n",
    "    validate_at_steps = [temp * x for x in range(1, nv + 1)]\n",
    "    \n",
    "    if CONFIG.USE_FGM:\n",
    "        fgm = FGM(model, epsilon=1, emb_name='word_embeddings.')\n",
    "\n",
    "    train_loss = 0\n",
    "    for step, batch in tqdm(enumerate(train_dataloader),\n",
    "                            total=len(train_dataloader),\n",
    "                            desc='training'):\n",
    "        # set model.eval() every time during training\n",
    "        model.train()\n",
    "\n",
    "        # unpack the batch contents and push them to the device (cuda or cpu).\n",
    "        b_input_ids = batch['input_ids'].to(device)\n",
    "        b_attention_mask = batch['attention_mask'].to(device)\n",
    "        b_labels = batch['labels'].to(device)\n",
    "\n",
    "        # forward pass\n",
    "        logits = model(input_ids=b_input_ids, attention_mask=b_attention_mask)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = criterion(logits, b_labels)\n",
    "        loss = loss / CONFIG.ACCUMULATION_STEPS\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # fgm attack\n",
    "        if CONFIG.USE_FGM:\n",
    "            fgm.attack()\n",
    "            logits_adv = model(input_ids=b_input_ids, attention_mask=b_attention_mask)\n",
    "            loss_adv = criterion(logits_adv, b_labels)\n",
    "            loss_adv.backward()\n",
    "            fgm.restore()\n",
    "\n",
    "        if (step+1) % CONFIG.ACCUMULATION_STEPS == 0:\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            # clear accumulated gradients\n",
    "            optimizer.zero_grad()\n",
    "            # update scheduler\n",
    "            scheduler.step()\n",
    "\n",
    "        if step in validate_at_steps:\n",
    "            print(f'-- Step: {step}')\n",
    "            _ = val_fn(model, valid_dataloader, criterion)\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "    print('Training loss:', avg_train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_fn(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kfold training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits=CONFIG.N_FOLDS, shuffle=True)\n",
    "for fold, (tr_ind, val_ind) in enumerate(folds.split(df_train, df_train['label'])):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train = df_train.loc[tr_ind]\n",
    "    valid = df_train.loc[val_ind]\n",
    "    \n",
    "    train_ds = SentiDataset(train, tr_ind)\n",
    "    valid_ds = SentiDataset(valid, val_ind)\n",
    "    train_dl = DataLoader(train_ds, batch_size=CONFIG.BATCH_SIZE)\n",
    "    valid_dl = DataLoader(valid_ds, batch_size=CONFIG.BATCH_SIZE)\n",
    "    \n",
    "    torch.manual_seed(CONFIG.SEED)\n",
    "    if len(CONFIG.CLASSES_WEIGHTS) > 0:\n",
    "        criterion = nn.CrossEntropyLoss(weight=torch.tensor(CONFIG.CLASSES_WEIGHTS, dtype=torch.float).to(device))\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    model = Model()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    if CONFIG.FULL_FINETUNING:\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\": 0.001,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = optim.AdamW(optimizer_parameters, lr=CONFIG.LR)\n",
    "\n",
    "    num_training_steps = len(train_dl) * CONFIG.EPOCHS\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=CONFIG.N_WARMUP,\n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "\n",
    "    min_avg_val_loss = float('inf')\n",
    "    for epoch in range(CONFIG.EPOCHS):\n",
    "        train_fn(model, train_dl, valid_dl, criterion, optimizer, scheduler, epoch)\n",
    "        avg_val_loss, _ = val_fn(model, valid_dl, criterion)\n",
    "\n",
    "        if CONFIG.SAVE_BEST_ONLY:\n",
    "            if avg_val_loss < min_avg_val_loss:\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_val_mse_score = avg_val_loss\n",
    "                model_name = f'models/fold{fold}_best_model'\n",
    "                torch.save(best_model.state_dict(), model_name + '.pt')\n",
    "                print(f'--- Best Model. Val loss: {min_avg_val_loss} -> {avg_val_loss}')\n",
    "                min_avg_val_loss = avg_val_loss\n",
    "                \n",
    "    model = Model()\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(f'models/fold{fold}_best_model.pt'))\n",
    "    valid_probs = predict_prob(model, valid_dl)\n",
    "    valid_df = valid.copy()\n",
    "    for i in range(CONFIG.NUM_CLASSES):\n",
    "        valid_df[f'p{i}'] = valid_probs[:, i]\n",
    "    valid_df['pred'] = valid_probs.argmax(axis=1)\n",
    "    valid_df.to_pickle(f'oofs/fold{fold}_oof.pickle')\n",
    "    \n",
    "    acc, f1 = metric_fn(valid['label'], valid_df['pred'])\n",
    "    \n",
    "    used_time = time.time() - start_time\n",
    "    \n",
    "    print(f'fold {fold} score: acc={acc}, f1={f1} used_time: {used_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof = list()\n",
    "for fold in range(CONFIG.N_FOLDS):\n",
    "    oof.append(pd.read_pickle(f'oofs/fold{fold}_oof.pickle'))\n",
    "df_oof = pd.concat(oof)\n",
    "df_oof = df_oof.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, f1 = metric_fn(df_train['label'], df_oof['pred'])\n",
    "print(f'OOF acc={acc}, f1={f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
